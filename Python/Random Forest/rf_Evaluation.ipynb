{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>few_clouds</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>0.039816</td>\n",
       "      <td>0.038235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scattered_clouds</td>\n",
       "      <td>0.103158</td>\n",
       "      <td>0.054627</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>broken_clouds</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.157038</td>\n",
       "      <td>0.123008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sky_is_clear</td>\n",
       "      <td>0.182568</td>\n",
       "      <td>0.068342</td>\n",
       "      <td>0.099455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>overcast_clouds</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.003687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mist</td>\n",
       "      <td>0.061705</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.087122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>drizzle</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>moderate_rain</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.018349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>light_intensity_drizzle</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>light_rain</td>\n",
       "      <td>0.032768</td>\n",
       "      <td>0.036755</td>\n",
       "      <td>0.034648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fog</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.022075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>haze</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>heavy_snow</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>heavy_intensity_drizzle</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>heavy_intensity_rain</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>light_rain_and_snow</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>snow</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>light_snow</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>proximity_thunderstorm</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>thunderstorm_with_rain</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>thunderstorm_with_heavy_rain</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>thunderstorm_with_light_rain</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>very_heavy_rain</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dust</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           class  precision    recall  f1-score\n",
       "0                     few_clouds   0.036775  0.039816  0.038235\n",
       "1               scattered_clouds   0.103158  0.054627  0.071429\n",
       "2                  broken_clouds   0.101100  0.157038  0.123008\n",
       "3                   sky_is_clear   0.182568  0.068342  0.099455\n",
       "4                overcast_clouds   0.009009  0.002317  0.003687\n",
       "5                           mist   0.061705  0.148148  0.087122\n",
       "6                        drizzle   0.000000  0.000000  0.000000\n",
       "7                  moderate_rain   0.021429  0.016043  0.018349\n",
       "8        light_intensity_drizzle   0.012048  0.012500  0.012270\n",
       "9                     light_rain   0.032768  0.036755  0.034648\n",
       "10                           fog   0.021097  0.023148  0.022075\n",
       "11                          haze   0.000000  0.000000  0.000000\n",
       "12                    heavy_snow   0.500000  0.041667  0.076923\n",
       "13       heavy_intensity_drizzle   0.000000  0.000000  0.000000\n",
       "14          heavy_intensity_rain   0.000000  0.000000  0.000000\n",
       "15           light_rain_and_snow   0.000000  0.000000  0.000000\n",
       "16                          snow   0.142857  0.052632  0.076923\n",
       "17                    light_snow   0.022140  0.077922  0.034483\n",
       "18        proximity_thunderstorm   0.000000  0.000000  0.000000\n",
       "19                  thunderstorm   0.000000  0.000000  0.000000\n",
       "20        thunderstorm_with_rain   0.000000  0.000000  0.000000\n",
       "21  thunderstorm_with_heavy_rain   0.000000  0.000000  0.000000\n",
       "22  thunderstorm_with_light_rain   0.000000  0.000000  0.000000\n",
       "23               very_heavy_rain   1.000000  0.411765  0.583333\n",
       "24                          dust   1.000000  0.250000  0.400000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_folds = {\n",
    "                'fold_0' : pd.read_csv(f'metrics_fold_0.csv').drop('support',axis=1),\n",
    "                'fold_1' : pd.read_csv(f'metrics_fold_1.csv').drop('support',axis=1),\n",
    "                'fold_2' : pd.read_csv(f'metrics_fold_2.csv').drop('support',axis=1),\n",
    "                'fold_3' : pd.read_csv(f'metrics_fold_3.csv').drop('support',axis=1),\n",
    "                'fold_4' : pd.read_csv(f'metrics_fold_4.csv').drop('support',axis=1),\n",
    "                }\n",
    "\n",
    "metrics_folds.get('fold_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMicro Avg (Micro Average)\\n    É calculado agregando as contagens de verdadeiros positivos, falsos positivos e falsos negativos de todas as classes e, em seguida, calculando as métricas de precisão, recall e f1-score com base nesses totais agregados.\\n    É útil quando é desejado dar peso igual a todas as instâncias, independentemente da classe.\\n\\n\\nMacro Avg (Macro Average):\\n    O macro avg é calculado calculando as métricas de precisão, recall e f1-score separadamente para cada classe e, em seguida, tirando a média desses valores.\\n    Dá igual peso a todas as classes, independentemente de sua distribuição no conjunto de dados. Cada classe contribui com a mesma quantidade para as métricas de média.\\n\\n\\nWeighted Avg (Weighted Average):\\n    O weighted avg é semelhante ao macro avg, mas dá pesos diferentes a cada classe com base na proporção de amostras de cada classe no conjunto de dados.\\n    Pondera as métricas de acordo com o número de amostras de cada classe. Classes com mais amostras têm mais impacto nas métricas de média.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Micro Avg (Micro Average)\n",
    "    É calculado agregando as contagens de verdadeiros positivos, falsos positivos e falsos negativos de todas as classes e, em seguida, calculando as métricas de precisão, recall e f1-score com base nesses totais agregados.\n",
    "    É útil quando é desejado dar peso igual a todas as instâncias, independentemente da classe.\n",
    "\n",
    "\n",
    "Macro Avg (Macro Average):\n",
    "    O macro avg é calculado calculando as métricas de precisão, recall e f1-score separadamente para cada classe e, em seguida, tirando a média desses valores.\n",
    "    Dá igual peso a todas as classes, independentemente de sua distribuição no conjunto de dados. Cada classe contribui com a mesma quantidade para as métricas de média.\n",
    "\n",
    "\n",
    "Weighted Avg (Weighted Average):\n",
    "    O weighted avg é semelhante ao macro avg, mas dá pesos diferentes a cada classe com base na proporção de amostras de cada classe no conjunto de dados.\n",
    "    Pondera as métricas de acordo com o número de amostras de cada classe. Classes com mais amostras têm mais impacto nas métricas de média.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = {}\n",
    "for fold in metrics_folds.keys():\n",
    "    evaluation[fold] = { \n",
    "                        'precision': {'mean': np.mean(metrics_folds.get(fold)['precision']), 'std': np.std(metrics_folds.get(fold)['precision'])},\n",
    "                        'recall': {'mean': np.mean(metrics_folds.get(fold)['recall']), 'std': np.std(metrics_folds.get(fold)['recall'])},\n",
    "                        'f1-score': {'mean': np.mean(metrics_folds.get(fold)['f1-score']), 'std': np.std(metrics_folds.get(fold)['f1-score'])} \n",
    "                         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': {'mean': 0.0696028686270627, 'std': 0.11183588969344546},\n",
       " 'recall': {'mean': 0.07605091390836104, 'std': 0.11848521382812759},\n",
       " 'f1-score': {'mean': 0.04795003764730244, 'std': 0.06319020217861634}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation['fold_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fold_0</th>\n",
       "      <td>0.032059</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.016483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold_1</th>\n",
       "      <td>0.069603</td>\n",
       "      <td>0.076051</td>\n",
       "      <td>0.04795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold_2</th>\n",
       "      <td>0.116732</td>\n",
       "      <td>0.080266</td>\n",
       "      <td>0.07864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold_3</th>\n",
       "      <td>0.129866</td>\n",
       "      <td>0.055709</td>\n",
       "      <td>0.067278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold_4</th>\n",
       "      <td>0.128736</td>\n",
       "      <td>0.108964</td>\n",
       "      <td>0.047099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095399</td>\n",
       "      <td>0.084823</td>\n",
       "      <td>0.05149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision    recall  f1-score\n",
       "fold_0  0.032059  0.103125  0.016483\n",
       "fold_1  0.069603  0.076051   0.04795\n",
       "fold_2  0.116732  0.080266   0.07864\n",
       "fold_3  0.129866  0.055709  0.067278\n",
       "fold_4  0.128736  0.108964  0.047099\n",
       "mean    0.095399  0.084823   0.05149"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame(columns = ['precision', 'recall','f1-score',], index=['fold_0','fold_1','fold_2','fold_3','fold_4'])\n",
    "\n",
    "for fold in evaluation:\n",
    "    for metric in evaluation.get(fold).keys():\n",
    "        compare.loc[fold, 'precision'] = evaluation.get(fold).get('precision').get('mean')\n",
    "\n",
    "        compare.loc[fold, 'recall'] = evaluation.get(fold).get('recall').get('mean')\n",
    "        \n",
    "        compare.loc[fold, 'f1-score'] = evaluation.get(fold).get('f1-score').get('mean')\n",
    "\n",
    "compare.loc['mean','precision'] = compare['precision'].mean()\n",
    "compare.loc['mean','recall'] = compare['recall'].mean()\n",
    "compare.loc['mean','f1-score'] = compare['f1-score'].mean()\n",
    "\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
